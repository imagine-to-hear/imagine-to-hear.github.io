<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>
  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>ImagineToHear</title>

  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet" />
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <style>
    td {
      vertical-align: middle;
      min-width: 220px;
    }
    audio {
      height: 50px;
      width: 20vw;
      min-width: 70px;
      max-width: 220px;
    }
  </style>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>

</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop text-center">
      <h1 class="display-4 fw-bold">Imagine to Hear: Auditory Knowledge Generation can be an Effective Assistant for Language Models</h1>
    </div>
  </div>
</section>

<section class="container pt-5 mt-5 shadow p-5 mb-5 bg-white rounded">
  <h2 class="text-center">Case Study</h2>
  <p class="mt-4">In this section, we provide samples of prompted control over the singer gender. The results are from Prompt-Singer with finetuned FLAN-T5 large text encoder.</p>
  <div class="table-responsive mt-4">
    <table class="table table-hover">
      <thead>
        <tr>
          <th class="text-center">Rejection</th>
          <th class="text-center">Label</th>
          <th class="text-center">Output</th>
          <th class="text-center">Audio</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td class="text-center text-danger">X</td>
          <td class="text-center">Cat</td>
          <td class="text-center text-danger">Dog</td>
          <td class="text-center">
            <audio controls controlslist="nodownload">
              <source src='data/gender/0_male.wav' type="audio/wav">
              Your browser does not support the audio element.
            </audio>
          </td>
        </tr>
        <tr>
          <td class="text-center text-success">O</td>
          <td class="text-center">Cat</td>
          <td class="text-center text-success">Cat</td>
          <td class="text-center">
            <audio controls controlslist="nodownload">
              <source src='data/gender/0_male.wav' type="audio/wav">
              Your browser does not support the audio element.
            </audio>
          </td>
        </tr>
      </tbody>
    </table>
  </div>
</section>

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="text-center">
      <h2 class="title is-3">Abstract</h2>
      <p class="fs-5 text-justify">
        The advancement of pretrained language models has significantly improved the state of the art in various language-related tasks.
        However, since the models have been trained on text-only corpora, they struggle with tasks requiring auditory commonsense knowledge.
        Previous work addresses this problem by augmenting the language model to retrieve knowledge from an external database containing auditory data.
        This approach has many limitations, such as the potential lack of relevant audio in databases and the high costs associated with constructing and querying the databases.
        To address these issues, we propose Imagine to Hear, a novel approach that dynamically generates auditory knowledge using generative models.
        Our framework employs a hierarchical architecture that effectively integrates auditory knowledge, incorporating a CLAP-based rejection system for quality control.
        Through experiments, we demonstrate that our method achieves state-of-the-art performance on AuditoryBench without relying on external databases, and improves performance on GLUE and CommonsenseQA benchmark, highlighting the effectiveness of our generation-based approach.
      </p>
    </div>
  </div>
</section>

<section class="container pt-5 mt-5 shadow p-5 mb-5 bg-white rounded">
  <h2 class="text-center">Model Architecture</h2>
  <div class="text-center mt-4">
    <img src="static/images/ITH_model.png" alt="Model Architecture" class="img-fluid">
  </div>
  <p class="fs-5 text-justify mt-4">
    Our model features a hierarchical architecture comprising three main components: the Imagination Module, which generates auditory representations; the Language Encoder, which processes textual inputs; and the Fusion Module, which integrates auditory and linguistic information.
  </p>
</section>

<section class="container pt-5 mt-5 shadow p-5 mb-5 bg-white rounded">
  <h2 class="text-center">Rejection System</h2>
  <div class="text-center mt-4">
    <img src="static/images/ITH_rejection.png" alt="Rejection System" class="img-fluid">
  </div>
  <p class="fs-5 text-justify mt-4">
    An iterative refinement process powered by a CLAP-based rejection system ensures high-quality auditory knowledge generation. This architecture enables retrieval-free auditory augmentation that overcomes the limitations of retrieval-based approaches.
  </p>
</section>

<footer class="footer">
  <div class="container text-center">
    <p>
      This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
      You are free to borrow the source code of this website, we just ask that you link back to this page in the footer.
      This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
    </p>
  </div>
</footer>

</body>
</html>
